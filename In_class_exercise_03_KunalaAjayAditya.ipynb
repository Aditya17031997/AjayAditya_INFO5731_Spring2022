{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya17031997/AjayAditya_INFO5731_Spring2022/blob/main/In_class_exercise_03_KunalaAjayAditya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAQLi-1fm_0"
      },
      "source": [
        "## The third In-class-exercise (2/22/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54nWB2njfm_7"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ1XM2vffm_9"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "c3sv1sHsfm__",
        "outputId": "035135c3-2cd3-4f56-ff7b-52e5743933df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPlease write you answer here:\\n\\nThe most amazing text mining topic I observed is information Extraction. The procedure is mostly concerned with feature selection.\\n\\nFeature selection is a process that dynamically selects the qualities of your data that have the greatest impact on the prediction variable or output of interest.\\nAccuracy of variety of models, most notably linear and logistic regression can be lowered due to the existence of irrelevant variables in our data.\\n\\nThere are several types of features. Among them, I have considered below. Text data or word features, Phrase Patterns, Numerical data, and Categorical data.\\n\\nI have performed many text mining operations such as tokenization, feature extraction and removal of stop words on a sample dataset.\\n\\nTokenization breaks down a document into its constituent atomic components. I am interested in tokenizing statement to words in this scenario. To begin, we must split the statement down into words and Calculate the frequency i.e the number of times a word appears.\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "The most amazing text mining topic I observed is information Extraction. The procedure is mostly concerned with feature selection.\n",
        "\n",
        "Feature selection is a process that dynamically selects the qualities of your data that have the greatest impact on the prediction variable or output of interest.\n",
        "Accuracy of variety of models, most notably linear and logistic regression can be lowered due to the existence of irrelevant variables in our data.\n",
        "\n",
        "There are several types of features. Among them, I have considered below. Text data or word features, Phrase Patterns, Numerical data, and Categorical data.\n",
        "\n",
        "I have performed many text mining operations such as tokenization, feature extraction and removal of stop words on a sample dataset.\n",
        "\n",
        "Tokenization breaks down a document into its constituent atomic components. I am interested in tokenizing statement to words in this scenario. To begin, we must split the statement down into words and Calculate the frequency i.e the number of times a word appears.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEjv-kXOfnAC"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1N2jjoYfnAD",
        "outputId": "148cd3f9-dfe4-4838-a9aa-927301a01c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "       0\n",
            "-     39\n",
            "and   36\n",
            ":     34\n",
            "Data  31\n",
            "in    28\n",
            "with  27\n",
            "of    27\n",
            "to    24\n",
            ",     23\n",
            "for   23\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "!pip3 install nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "%matplotlib inline\n",
        "data_frame = pd.read_csv(r'/content/SampleData_KunalaAjayAditya.csv')\n",
        "data_frame.head()\n",
        "\n",
        "title = data_frame[\"title\"][0]\n",
        "# To print title\n",
        "extracted_tokens = nltk.wordpunct_tokenize(title)\n",
        "# To print extracted tokens\n",
        "# Using Title in the data frame and Tokenize it into words  \n",
        "# and finding out count of each words in the dictionary\n",
        "words_dict = {}\n",
        "for each_value in data_frame['title']:\n",
        "    extracted_tokens = nltk.wordpunct_tokenize(each_value)\n",
        "    for exac_token in extracted_tokens:\n",
        "        if exac_token in words_dict:\n",
        "            count_of_words = words_dict[exac_token]\n",
        "            count_of_words = count_of_words + 1\n",
        "            words_dict[exac_token] = count_of_words\n",
        "        else:\n",
        "            words_dict[exac_token] = 1\n",
        "\n",
        "#To print the frequency of words that exists\n",
        "\n",
        "freqency_of_words = pd.DataFrame.from_dict(words_dict, orient = 'index')\n",
        "print(freqency_of_words.sort_values(by = 0, ascending=False).head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m9rHZUkfnAH"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhZRMoBefnAI",
        "outputId": "e10aaff5-8f2d-4d7c-af11-d3605874639b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/laptopcheckout/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An Exploration of R, Yelp, and the Search for ...</td>\n",
              "      <td>5 points by Rogerh91 6 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>an,exploration,of,r,,,yelp,and,the,search,for,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deep Advances in Generative Modeling</td>\n",
              "      <td>7 points by gwulfs 15 hours ago  | 1 comment</td>\n",
              "      <td>1</td>\n",
              "      <td>deep,advances,in,generative,modeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spark Pipelines: Elegant Yet Powerful</td>\n",
              "      <td>3 points by aouyang1 9 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>spark,pipelines,:,elegant,yet,powerful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shit VCs Say</td>\n",
              "      <td>3 points by Argentum01 10 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>shit,vcs,say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Python, Machine Learning, and Language Wars</td>\n",
              "      <td>4 points by pmigdal 17 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>python,machine,learning,language,wars</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  An Exploration of R, Yelp, and the Search for ...   \n",
              "1               Deep Advances in Generative Modeling   \n",
              "2              Spark Pipelines: Elegant Yet Powerful   \n",
              "3                                       Shit VCs Say   \n",
              "4        Python, Machine Learning, and Language Wars   \n",
              "\n",
              "                                             date  days  \\\n",
              "0     5 points by Rogerh91 6 hours ago  | discuss     1   \n",
              "1    7 points by gwulfs 15 hours ago  | 1 comment     1   \n",
              "2     3 points by aouyang1 9 hours ago  | discuss     1   \n",
              "3  3 points by Argentum01 10 hours ago  | discuss     1   \n",
              "4     4 points by pmigdal 17 hours ago  | discuss     1   \n",
              "\n",
              "                                              tokens  \n",
              "0  an,exploration,of,r,,,yelp,and,the,search,for,...  \n",
              "1               deep,advances,in,generative,modeling  \n",
              "2             spark,pipelines,:,elegant,yet,powerful  \n",
              "3                                       shit,vcs,say  \n",
              "4              python,machine,learning,language,wars  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "  \n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(('.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','/','-'))\n",
        "stop_words_freq_dict = {}\n",
        "def calculate_word_frequency(row):\n",
        "    data = row['title']\n",
        "    extracted_token_values = nltk.wordpunct_tokenize(data)\n",
        "    list_of_tokens = []\n",
        "    for single_token in extracted_token_values:\n",
        "        if single_token.lower() not in stop_words_freq_dict:\n",
        "            list_of_tokens.append(single_token.lower())\n",
        "            if single_token.lower() in stop_words_freq_dict:\n",
        "                count_of_tokens = stop_words_freq_dict[single_token.lower()]\n",
        "                count_of_tokens = count_of_tokens + 1\n",
        "                stop_words_freq_dict[single_token.lower()] = count_of_tokens\n",
        "            else:\n",
        "                stop_words_freq_dict[single_token.lower()] = 1\n",
        "    \n",
        "    return ','.join(list_of_tokens)\n",
        "\n",
        "data_frame['tokens'] = data_frame.apply(calculate_word_frequency,axis=1)\n",
        "data_frame.head()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fimNlKRWfnAK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "name": "In-class-exercise-03_KunalaAjayAditya.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}